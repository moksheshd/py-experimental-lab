{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import extras\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1043407b18371b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "postgres = {\n",
    "    'host': 'localhost',\n",
    "    'database': 'tenshi',\n",
    "    'username': 'postgres',\n",
    "    'password': 'postgres',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45e0c940ddbce9e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "source_connection = psycopg2.connect(f\"host={postgres['host']} dbname={postgres['database']} user={postgres['username']} password={postgres['password']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7977d73c05d25",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'checklist_ids': (373013004340813824, 1),\n",
    "    'use_case_ids': (1660291903, 1660291904)\n",
    "}\n",
    "\n",
    "def get_next_id(df: pd.DataFrame, column: str):\n",
    "    max_df_id = df[column].max()\n",
    "    if pd.isna(max_df_id):\n",
    "        return 1\n",
    "    return max_df_id + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5e02f86e12d6be0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# ETL: Facility\n",
    "\n",
    "FACILITY_QUERY = \"\"\"\n",
    "SELECT id, name FROM facilities WHERE id != -1;\n",
    "\"\"\"\n",
    "facility_df = pd.read_sql(FACILITY_QUERY, source_connection, params=params)\n",
    "new_facility_df = facility_df.copy()\n",
    "new_facility_df.rename(columns={'id': 'facility_id', 'name': 'facility_name'}, inplace=True)\n",
    "print(tabulate(new_facility_df, headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd16fe9f444545b2",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "CHECKLIST_QUERY = \"\"\"\n",
    "SELECT c.id as checklist_id, c.name, c.code, uc.id as use_case_id, uc.name as use_case_name, cfm.facilities_id  \n",
    "FROM checklists c JOIN use_cases uc ON uc.id = c.use_cases_id JOIN checklist_facility_mapping cfm ON cfm.checklists_id = c.id\n",
    "WHERE c.state = 'PUBLISHED' AND c.archived = FALSE AND c.use_cases_id IN %(use_case_ids)s AND c.id IN %(checklist_ids)s\n",
    "\"\"\"\n",
    "checklist_df = pd.read_sql(CHECKLIST_QUERY, source_connection, params=params)\n",
    "new_process_df = checklist_df.copy()\n",
    "new_process_df.rename(columns={'checklist_id': 'id', 'use_case_name': 'process_type', 'name': 'process_name',\n",
    "                               'facilities_id': 'facility_id'}, inplace=True)\n",
    "new_process_df.drop('code', axis=1, inplace=True)\n",
    "new_process_df.drop('use_case_id', axis=1, inplace=True)\n",
    "print(tabulate(new_process_df, headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "391675c312c3c87e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "STAGE_QUERY = \"\"\"\n",
    "SELECT s.id as stage_id, s.\"name\", s.checklists_id as checklist_id, s.order_tree FROM stages s JOIN checklists c ON c.id = s.checklists_id WHERE s.archived = FALSE AND c.id IN %(checklist_ids)s ORDER BY c.id, s.order_tree\n",
    "\"\"\"\n",
    "stage_df = pd.read_sql(STAGE_QUERY, source_connection, params=params)\n",
    "new_stage_df = stage_df.copy()\n",
    "new_stage_df.rename(columns={'stage_id': 'id', 'name': 'stage_name', 'checklist_id': 'process_id'}, inplace=True)\n",
    "new_stage_df.drop('order_tree', axis=1, inplace=True)\n",
    "new_stage_df['stage_type'] = ''\n",
    "print(tabulate(new_stage_df, headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c3980352c75c51",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "TASK_QUERY = \"\"\"\n",
    "SELECT t.id as task_id, t.name, t.order_tree, t.stages_id as stage_id, s.checklists_id as checklist_id FROM tasks t JOIN stages s ON s.id = t.stages_id JOIN checklists c ON c.id = s.checklists_id WHERE t.archived = FALSE AND s.archived = FALSE AND c.id IN %(checklist_ids)s ORDER BY c.id, s.order_tree, t.order_tree \n",
    "\"\"\"\n",
    "task_df = pd.read_sql(TASK_QUERY, source_connection, params=params)\n",
    "new_step_df = task_df.copy()\n",
    "\n",
    "print(tabulate(task_df, headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "PARAMETER_QUERY = \"\"\"\n",
    "SELECT p.id as parameter_id, p.\"label\" AS name, p.\"data\", p.\"type\", p.order_tree, p.tasks_id as task_id, t.stages_id as stage_id, s.checklists_id as checklist_id FROM parameters p JOIN tasks t ON t.id = p.tasks_id JOIN stages s ON s.id = t.stages_id JOIN checklists c ON c.id = s.checklists_id WHERE p.archived = FALSE  AND t.archived = FALSE AND s.archived = FALSE AND c.id IN %(checklist_ids)s ORDER BY c.id, s.order_tree, t.order_tree, p.order_tree\n",
    "\"\"\"\n",
    "parameter_df = pd.read_sql(PARAMETER_QUERY, source_connection, params=params)\n",
    "new_step_attribute_df = pd.DataFrame(\n",
    "    columns=['id', 'step_id', 'data_type_id', 'attribute_label', 'resource_id', 'expected_value1', 'expected_value2',\n",
    "             'comparison_operator', 'resource_type'])\n",
    "\n",
    "new_step_attribute_data_types_df = pd.DataFrame(\n",
    "    columns=['data_type_id', 'measurement_type', 'measurement_unit', 'measurement_description'])\n",
    "\n",
    "print(tabulate(parameter_df, headers='keys', tablefmt='pretty'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7b3cc941ebbec49d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "TASK_EXECUTION_QUERY = \"\"\"\n",
    "SELECT te.id AS id, t.id AS task_id, TO_TIMESTAMP(te.started_at) AS started_at, TO_TIMESTAMP(te.ended_at) AS ended_at, te.state AS state, concat( tsu.first_name, ' ', tsu.last_name, ' ( ID: ', tsu.employee_id, ')' ) AS started_by FROM task_executions te JOIN tasks t ON t.id = te.tasks_id JOIN stages s ON s.id = t.stages_id JOIN checklists c ON c.id = s.checklists_id JOIN jobs j ON j.id = te.jobs_id JOIN users tsu ON tsu.id = te.started_by WHERE t.archived = FALSE AND s.archived = FALSE AND c.id IN %(checklist_ids)s ORDER BY c.id, s.order_tree, t.order_tree\n",
    "\"\"\"\n",
    "task_execution_df = pd.read_sql(TASK_EXECUTION_QUERY, source_connection, params=params)\n",
    "executed_step_df = task_execution_df.copy()\n",
    "print(tabulate(task_execution_df, headers='keys', tablefmt='pretty'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6fc32dd63bbfde87"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc37324ee77959",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parameter_types = ('INSTRUCTION', 'MATERIAL')\n",
    "# Filter to just instructions \n",
    "instruction_df = parameter_df[parameter_df['type'] == 'INSTRUCTION']\n",
    "\n",
    "# Compile regex once \n",
    "regex = re.compile(r'<.*?>')\n",
    "\n",
    "# Remove HTML tags in a vectorized manner and create a new 'clean_text' column\n",
    "instruction_df['instruction'] = instruction_df['data'].apply(lambda x: re.sub(regex, '', x['text']))\n",
    "\n",
    "# Group by 'task_id' and 'type', then join the texts together\n",
    "grouped = instruction_df.groupby(['task_id', 'type'])['instruction'].apply('\\n'.join).reset_index()\n",
    "\n",
    "# Filter out only the 'INSTRUCTION' type\n",
    "instructions = grouped[grouped['type'] == 'INSTRUCTION']\n",
    "\n",
    "new_step_df = new_step_df.merge(instructions[['task_id', 'instruction']], on='task_id', how='left')\n",
    "\n",
    "new_step_df.rename(columns={'task_id': 'id', 'name': 'step_name'}, inplace=True)\n",
    "new_step_df.drop('order_tree', axis=1, inplace=True)\n",
    "new_step_df.drop('stage_id', axis=1, inplace=True)\n",
    "new_step_df.drop('checklist_id', axis=1, inplace=True)\n",
    "\n",
    "print(tabulate(new_step_df, headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5116e0a86e3e8d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def append_to_df(new_rows_attribute_data_types, new_rows_attribute, attribute_data_types_df, attribute_df):\n",
    "    new_rows_data_types_df = pd.DataFrame(new_rows_attribute_data_types)\n",
    "    new_rows_attribute_df = pd.DataFrame(new_rows_attribute)\n",
    "    attribute_data_types_df = pd.concat([attribute_data_types_df, new_rows_data_types_df], ignore_index=True)\n",
    "    attribute_df = pd.concat([attribute_df, new_rows_attribute_df], ignore_index=True)\n",
    "    return  attribute_data_types_df, attribute_df\n",
    "\n",
    "def create_row_attribute_data_type(data_type_id, measurement_type, measurement_unit, measurement_description):\n",
    "    return {\n",
    "        'data_type_id': data_type_id,\n",
    "        'measurement_type': measurement_type,\n",
    "        'measurement_unit': measurement_unit,\n",
    "        'measurement_description': measurement_description\n",
    "    }\n",
    "\n",
    "def create_row_attribute(attribute_id, step_id, data_type_id, attribute_label, expected_value1, expected_value2, comparison_operator, resource_id, resource_type, reference_id):\n",
    "    return {\n",
    "        'id': attribute_id,\n",
    "        'step_id': step_id,\n",
    "        'data_type_id': data_type_id,\n",
    "        'attribute_label': attribute_label,\n",
    "        'expected_value1': expected_value1,\n",
    "        'expected_value2': expected_value2,\n",
    "        'comparison_operator': comparison_operator,\n",
    "        'resource_id': resource_id,\n",
    "        'resource_type': resource_type,\n",
    "        'reference_id': reference_id\n",
    "    }\n",
    "\n",
    "def create_rows(parameter, identifier):\n",
    "    new_rows_attribute_data_type = []\n",
    "    new_rows_attribute = []\n",
    "    measurement_unit = expected_value1 = expected_value2 = comparison_operator = resource_id = resource_type = reference_id = measurement_type = None\n",
    "    parameter_type, step_id, name = parameter['type'], parameter['stage_id'], parameter['name']\n",
    "    if parameter_type not in (['SINGLE_SELECT', 'CHECKLIST', 'MULTISELECT']):\n",
    "        is_parameter_type_handled = True\n",
    "        if parameter_type == 'NUMBER':\n",
    "            measurement_type = 'integer'\n",
    "        elif parameter_type == 'SHOULD_BE':\n",
    "            measurement_type = 'float'\n",
    "            operator = parameter['data']['operator']\n",
    "            if operator == 'EQUAL_TO':\n",
    "                expected_value1 = parameter['data']['value']\n",
    "                comparison_operator = '='\n",
    "            elif operator == 'LESS_THAN':\n",
    "                expected_value1 = parameter['data']['value']\n",
    "                comparison_operator = '<'\n",
    "            elif operator == 'LESS_THAN_EQUAL_TO':\n",
    "                expected_value1 = parameter['data']['value']\n",
    "                comparison_operator = '<='\n",
    "            elif operator == 'MORE_THAN':\n",
    "                expected_value1 = parameter['data']['value']\n",
    "                comparison_operator = '>'\n",
    "            elif operator == 'MORE_THAN_EQUAL_TO':\n",
    "                expected_value1 = parameter['data']['value']\n",
    "                comparison_operator = '>='\n",
    "            elif operator == 'BETWEEN':                \n",
    "                expected_value1 = parameter['data']['lowerValue']\n",
    "                expected_value2 = parameter['data']['upperValue']\n",
    "                comparison_operator = 'between'\n",
    "        elif parameter_type == 'SINGLE_LINE' or parameter_type == 'MULTI_LINE':\n",
    "            measurement_type = 'text'\n",
    "        elif parameter_type == 'DATE' or parameter_type == 'DATE_TIME':\n",
    "            measurement_type = parameter_type.lower()\n",
    "        elif parameter_type == 'YES_NO':\n",
    "            measurement_type = 'boolean'\n",
    "        elif parameter_type == 'RESOURCE':\n",
    "            measurement_type = 'text'\n",
    "            resource_type = parameter['data']['collection']\n",
    "        else:\n",
    "            print(f\"Parameter type: {parameter_type} is not implemented\")\n",
    "            is_parameter_type_handled = False\n",
    "        if is_parameter_type_handled:    \n",
    "            new_row_attribute_data_type = create_row_attribute_data_type(identifier, measurement_type, measurement_unit, name)\n",
    "            new_row_attribute = create_row_attribute(identifier, step_id, new_row_attribute_data_type['data_type_id'], name, expected_value1, expected_value2, comparison_operator, resource_id, resource_type, reference_id)\n",
    "            new_rows_attribute_data_type.append(new_row_attribute_data_type)\n",
    "            new_rows_attribute.append(new_row_attribute)\n",
    "    else:\n",
    "        if parameter_type == 'SINGLE_SELECT' or parameter_type == 'CHECKLIST' or parameter_type == 'MULTISELECT':\n",
    "            measurement_type = 'boolean'\n",
    "            for choice in row['data']:\n",
    "                name = parameter['name'] + ' - ' + choice['name']\n",
    "                reference_id = choice['id']\n",
    "                new_row_attribute_data_type = create_row_attribute_data_type(identifier, measurement_type, measurement_unit, name)\n",
    "                new_row_attribute = create_row_attribute(identifier, step_id, new_row_attribute_data_type['data_type_id'], name, expected_value1, expected_value2, comparison_operator, resource_id, resource_type, reference_id)\n",
    "                new_rows_attribute_data_type.append(new_row_attribute_data_type)\n",
    "                new_rows_attribute.append(new_row_attribute)\n",
    "                identifier += 1\n",
    "        else:\n",
    "            print(f\"Parameter type: {parameter_type} is not implemented.\")\n",
    "                \n",
    "    return new_rows_attribute_data_type, new_rows_attribute\n",
    "\n",
    "next_id = get_next_id(new_step_attribute_data_types_df, 'data_type_id')\n",
    "relevant_parameter_df = parameter_df[~parameter_df['type'].isin(['INSTRUCTION', 'MATERIAL', 'MEDIA', 'SIGNATURE', 'FILE_UPLOAD'])]\n",
    "for index, row in relevant_parameter_df.iterrows():\n",
    "    attribute_data_types, attributes = create_rows(row, next_id)\n",
    "    if len(attribute_data_types) != 0 and len(attributes) != 0:\n",
    "        new_step_attribute_data_types_df, new_step_attribute_df = append_to_df(attribute_data_types, attributes, new_step_attribute_data_types_df, new_step_attribute_df)\n",
    "    next_id += len(attribute_data_types)\n",
    "\n",
    "print(tabulate(new_step_attribute_data_types_df, headers='keys', tablefmt='pretty'))\n",
    "print(tabulate(new_step_attribute_df, headers='keys', tablefmt='pretty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "executed_step_df.rename(columns={'id': 'execution_id', 'task_id': 'step_id', 'started_at': 'execution_start_time', 'ended_at': 'execution_end_time', 'state': 'status', 'started_by': 'executed_by_employee_id'  }, inplace=True)\n",
    "executed_step_df['batch_id'] = None\n",
    "print(tabulate(executed_step_df, headers='keys', tablefmt='pretty'))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "48804d634e868135"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
